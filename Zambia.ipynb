{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe2b7GJ4sRmcclz83VZWgp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yayesh16/solar-challenge-week/blob/eda-zambia/Zambia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xzj9qzmxi6-H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbxrK7c1r9kX",
        "outputId": "d9f5dee5-cbf6-4f35-901a-2fe2b40016f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yayesh16/solar-challenge-week.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QHHpxPsttgz",
        "outputId": "fc74e653-05f7-46a7-dceb-f8d82471affc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'solar-challenge-week'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 16 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (16/16), done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd solar-challenge-week/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHmk0FIrt9oG",
        "outputId": "2569e394-f8ce-4a06-ae8a-2e0914bbd27a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/solar-challenge-week\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data"
      ],
      "metadata": {
        "id": "-C6veO9cud5k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/10acadamy/Solar data/zambia.csv\" data/"
      ],
      "metadata": {
        "id": "xLgZ3jlE2EiA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3tBb7yqAbpG",
        "outputId": "7a70775e-b7ea-489c-9c8d-d37f7cc32b2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zambia.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import zscore\n",
        "import os\n",
        "from windrose import WindroseAxes\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "COUNTRY_NAME = \"Zambia\"\n",
        "DATA_PATH = f\"data/zambia.csv\"\n",
        "CLEANED_DATA_PATH = f\"data/zambia_clean.csv\"\n",
        "\n",
        "print(f\"Starting EDA for zambia\")\n",
        "print(f\"Attempting to load data from: data/zambia.csv\")\n",
        "\n",
        "# --- 2. Data Loading ---\n",
        "try:\n",
        "    df = pd.read_csv(\"data/zambia.csv\")\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: data/zambia.csv not found. Please ensure the CSV file is in the 'data/' directory.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the data: {e}\")\n",
        "    exit()\n",
        "\n",
        "df_original = df.copy()\n",
        "\n",
        "# Convert 'Date (UTC)' to datetime and set as index\n",
        "timestamp_column_name = 'Date (UTC)'\n",
        "if timestamp_column_name in df.columns:\n",
        "    df[timestamp_column_name] = pd.to_datetime(df[timestamp_column_name], errors='coerce')\n",
        "    df.dropna(subset=[timestamp_column_name], inplace=True)\n",
        "    df.set_index(timestamp_column_name, inplace=True)\n",
        "    df.sort_index(inplace=True)\n",
        "    print(f\"{timestamp_column_name} column processed and set as index.\")\n",
        "    df.index.name = 'Timestamp'\n",
        "else:\n",
        "    print(f\"Warning: '{timestamp_column_name}' column not found. Please check your CSV column names.\")\n",
        "    print(\"Available columns:\", df.columns.tolist())\n",
        "\n",
        "# --- RENAME COLUMNS FOR CONSISTENCY WITH SCRIPT'S EXPECTATIONS ---\n",
        "# This map is based on typical IFC solar data column names.\n",
        "# If your CSV's column names differ, adjust the LEFT side of the 'key: value' pairs.\n",
        "column_rename_map = {\n",
        "    'GHI (W/m2)': 'GHI',\n",
        "    'DNI (W/m2)': 'DNI',\n",
        "    'DHI (W/m2)': 'DHI',\n",
        "    'Module Temp (C) (logger 1)': 'ModA',\n",
        "    'Module Temp (C) (logger 2)': 'ModB',\n",
        "    'Ambient Temp (C)': 'Tamb',\n",
        "    'Relative Humidity (%)': 'RH',\n",
        "    'Wind Speed (m/s)': 'WS',\n",
        "    'Wind Speed Gust (m/s)': 'WSgust',\n",
        "    'Wind Direction (deg)': 'WD',\n",
        "    'Barometric Pressure (mBar)': 'BP'\n",
        "}\n",
        "\n",
        "df.rename(columns={k: v for k, v in column_rename_map.items() if k in df.columns}, inplace=True)\n",
        "df_original.rename(columns={k: v for k, v in column_rename_map.items() if k in df_original.columns}, inplace=True)\n",
        "\n",
        "print(\"\\n--- Initial DataFrame Info ---\")\n",
        "df.info()\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# --- 3. Summary Statistics & Missing-Value Report ---\n",
        "print(\"\\n--- Summary Statistics for Numeric Columns ---\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\n--- Missing Value Report ---\")\n",
        "missing_values = df.isna().sum()\n",
        "missing_percentage = (df.isna().sum() / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_values,\n",
        "    'Missing Percentage': missing_percentage\n",
        "})\n",
        "print(missing_df[missing_df['Missing Count'] > 0].sort_values(by='Missing Percentage', ascending=False))\n",
        "\n",
        "high_null_cols = missing_percentage[missing_percentage > 5].index.tolist()\n",
        "if high_null_cols:\n",
        "    print(f\"\\nColumns with >5% nulls: {high_null_cols}\")\n",
        "else:\n",
        "    print(\"\\nNo columns with >5% nulls.\")\n",
        "\n",
        "# --- 4. Outlier Detection & Basic Cleaning ---\n",
        "print(\"\\n--- Outlier Detection and Cleaning ---\")\n",
        "\n",
        "zscore_cols = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
        "zscore_cols_existing = [col for col in zscore_cols if col in df.columns]\n",
        "\n",
        "df['cleaning_flag'] = 'original'\n",
        "\n",
        "for col in zscore_cols_existing:\n",
        "    if df[col].dtype in ['float64', 'int64']:\n",
        "        temp_series = df[col].dropna()\n",
        "        if not temp_series.empty:\n",
        "            z_scores = np.abs(zscore(temp_series))\n",
        "            outlier_mask = pd.Series(False, index=df.index)\n",
        "            outlier_mask.loc[temp_series.index] = (z_scores > 3)\n",
        "            df.loc[outlier_mask, 'cleaning_flag'] = 'outlier_flagged'\n",
        "            print(f\"Flagged {outlier_mask.sum()} outliers in column: {col}\")\n",
        "        else:\n",
        "            print(f\"Column '{col}' is entirely NaN, skipping Z-score calculation.\")\n",
        "    else:\n",
        "        print(f\"Skipping Z-score for non-numeric column: {col}\")\n",
        "\n",
        "key_columns_for_imputation = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust', 'Tamb', 'RH', 'BP']\n",
        "key_columns_for_imputation_existing = [col for col in key_columns_for_imputation if col in df.columns]\n",
        "\n",
        "for col in key_columns_for_imputation_existing:\n",
        "    if df[col].isna().sum() > 0:\n",
        "        if df[col].dtype in ['float64', 'int64']:\n",
        "            median_val = df[col].median()\n",
        "            df[col].fillna(median_val, inplace=True)\n",
        "            print(f\"Imputed missing values in '{col}' with median: {median_val:.2f}\")\n",
        "        else:\n",
        "            print(f\"Skipping imputation for non-numeric column with NaNs: {col}\")\n",
        "\n",
        "print(\"\\n--- Missing Value Report After Imputation ---\")\n",
        "print(df.isna().sum()[df.isna().sum() > 0])\n",
        "if df.isna().sum().sum() == 0:\n",
        "    print(\"No missing values remaining in the DataFrame.\")\n",
        "else:\n",
        "    print(\"Some missing values still remain (likely in non-key columns or after timestamp processing).\")\n",
        "\n",
        "try:\n",
        "    df.to_csv(CLEANED_DATA_PATH, index=True)\n",
        "    print(f\"\\nCleaned DataFrame exported to: {CLEANED_DATA_PATH}\")\n",
        "    print(\"Remember to add 'data/' to your .gitignore file to prevent committing CSVs.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error exporting cleaned data: {e}\")\n",
        "\n",
        "# --- 5. Time Series Analysis ---\n",
        "print(\"\\n--- Time Series Analysis ---\")\n",
        "\n",
        "time_series_cols = ['GHI', 'DNI', 'DHI', 'Tamb']\n",
        "time_series_cols_existing = [col for col in time_series_cols if col in df.columns]\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "for i, col in enumerate(time_series_cols_existing):\n",
        "    plt.subplot(len(time_series_cols_existing), 1, i + 1)\n",
        "    df[col].plot(title=f'{col} Over Time for zambia', grid=True)\n",
        "    plt.ylabel(col)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "if 'GHI' in df.columns:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    df['GHI'].resample('M').mean().plot(kind='bar', title=f'Average Monthly GHI for zambia', grid=True)\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel('Average GHI')\n",
        "    plt.show()\n",
        "\n",
        "if 'GHI' in df.columns:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    df.groupby(df.index.hour)['GHI'].mean().plot(title=f'Average Hourly GHI for zambia', grid=True)\n",
        "    plt.xlabel('Hour of Day')\n",
        "    plt.ylabel('Average GHI')\n",
        "    plt.xticks(range(0, 24))\n",
        "    plt.show()\n",
        "\n",
        "# --- 6. Cleaning Impact ---\n",
        "print(\"\\n--- Cleaning Impact Analysis ---\")\n",
        "\n",
        "if 'cleaning_flag' in df.columns and 'ModA' in df.columns and 'ModB' in df.columns:\n",
        "    df_original_flagged = df_original.copy()\n",
        "    if timestamp_column_name in df_original_flagged.columns:\n",
        "        df_original_flagged[timestamp_column_name] = pd.to_datetime(df_original_flagged[timestamp_column_name], errors='coerce')\n",
        "        df_original_flagged.dropna(subset=[timestamp_column_name], inplace=True)\n",
        "        df_original_flagged.set_index(timestamp_column_name, inplace=True)\n",
        "        df_original_flagged.index.name = 'Timestamp'\n",
        "\n",
        "    df_original_flagged['cleaning_flag_pre_clean'] = 'original'\n",
        "    for col in zscore_cols_existing:\n",
        "        if col in df_original_flagged.columns and df_original_flagged[col].dtype in ['float64', 'int64']:\n",
        "            temp_series_orig = df_original_flagged[col].dropna()\n",
        "            if not temp_series_orig.empty:\n",
        "                z_scores_orig = np.abs(zscore(temp_series_orig))\n",
        "                outlier_mask_orig = pd.Series(False, index=df_original_flagged.index)\n",
        "                outlier_mask_orig.loc[temp_series_orig.index] = (z_scores_orig > 3)\n",
        "                df_original_flagged.loc[outlier_mask_orig, 'cleaning_flag_pre_clean'] = 'outlier_flagged'\n",
        "            else:\n",
        "                print(f\"Original column '{col}' is entirely NaN, skipping outlier flagging for comparison.\")\n",
        "\n",
        "    print(\"\\nAverage ModA & ModB (Original Data, grouped by potential outlier flag):\")\n",
        "    if 'ModA' in df_original_flagged.columns and 'ModB' in df_original_flagged.columns:\n",
        "        print(df_original_flagged.groupby('cleaning_flag_pre_clean')[['ModA', 'ModB']].mean())\n",
        "    else:\n",
        "        print(\"ModA or ModB not found in original data for cleaning impact analysis.\")\n",
        "\n",
        "    print(\"\\nAverage ModA & ModB (Cleaned Data, overall mean after imputation):\")\n",
        "    if 'ModA' in df.columns and 'ModB' in df.columns:\n",
        "        print(df[['ModA', 'ModB']].mean())\n",
        "    else:\n",
        "        print(\"ModA or ModB not found in cleaned data for cleaning impact analysis.\")\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    if 'ModA' in df.columns and 'ModA' in df_original_flagged.columns:\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.histplot(df_original_flagged['ModA'].dropna(), color='skyblue', label='Original ModA', kde=True)\n",
        "        sns.histplot(df['ModA'], color='orange', label='Cleaned ModA', kde=True)\n",
        "        plt.title(f'Distribution of ModA (Original vs. Cleaned) for {COUNTRY_NAME}')\n",
        "        plt.legend()\n",
        "\n",
        "    if 'ModB' in df.columns and 'ModB' in df_original_flagged.columns:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        sns.histplot(df_original_flagged['ModB'].dropna(), color='lightgreen', label='Original ModB', kde=True)\n",
        "        sns.histplot(df['ModB'], color='red', label='Cleaned ModB', kde=True)\n",
        "        plt.title(f'Distribution of ModB (Original vs. Cleaned) for zambia')\n",
        "        plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Cannot perform cleaning impact analysis: 'cleaning_flag', 'ModA', or 'ModB' column missing.\")\n",
        "\n",
        "# --- 7. Correlation & Relationship Analysis ---\n",
        "print(\"\\n--- Correlation & Relationship Analysis ---\")\n",
        "\n",
        "correlation_cols = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'Tamb', 'RH', 'WS', 'WSgust', 'WD', 'BP']\n",
        "correlation_cols_existing = [col for col in correlation_cols if col in df.columns]\n",
        "\n",
        "if len(correlation_cols_existing) > 1:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(df[correlation_cols_existing].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title(f'Correlation Heatmap for zambia')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Not enough numeric columns for correlation heatmap.\")\n",
        "\n",
        "scatter_plots_config = [\n",
        "    {'x': 'WS', 'y': 'GHI'},\n",
        "    {'x': 'WSgust', 'y': 'GHI'},\n",
        "    {'x': 'WD', 'y': 'GHI'},\n",
        "    {'x': 'RH', 'y': 'Tamb'},\n",
        "    {'x': 'RH', 'y': 'GHI'}\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(18, 12))\n",
        "for i, config in enumerate(scatter_plots_config):\n",
        "    x_col = config['x']\n",
        "    y_col = config['y']\n",
        "    if x_col in df.columns and y_col in df.columns:\n",
        "        plt.subplot(2, 3, i + 1)\n",
        "        sns.scatterplot(data=df, x=x_col, y=y_col, alpha=0.6)\n",
        "        plt.title(f'{y_col} vs. {x_col} for zambia')\n",
        "        plt.xlabel(x_col)\n",
        "        plt.ylabel(y_col)\n",
        "    else:\n",
        "        print(f\"Skipping scatter plot: '{x_col}' or '{y_col}' not found.\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 8. Wind & Distribution Analysis ---\n",
        "print(\"\\n--- Wind & Distribution Analysis ---\")\n",
        "\n",
        "if 'WS' in df.columns and 'WD' in df.columns:\n",
        "    try:\n",
        "        ax = WindroseAxes.from_ax()\n",
        "        ax.bar(df['WD'], df['WS'], normed=True, opening=0.8, edgecolor='white')\n",
        "        ax.set_legend()\n",
        "        plt.title(f'Wind Rose Plot for zambia')\n",
        "        plt.show()\n",
        "        print(\"Wind rose plot generated.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate wind rose plot (might need 'windrose' library or data issues): {e}\")\n",
        "else:\n",
        "    print(\"Skipping wind rose plot: 'WS' or 'WD' column not found.\")\n",
        "\n",
        "histogram_cols = ['GHI', 'WS']\n",
        "histogram_cols_existing = [col for col in histogram_cols if col in df.columns]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "for i, col in enumerate(histogram_cols_existing):\n",
        "    plt.subplot(1, len(histogram_cols_existing), i + 1)\n",
        "    sns.histplot(df[col].dropna(), kde=True)\n",
        "    plt.title(f'Distribution of {col} for zambia')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 9. Temperature Analysis ---\n",
        "print(\"\\n--- Temperature Analysis ---\")\n",
        "\n",
        "if 'RH' in df.columns and 'Tamb' in df.columns and 'GHI' in df.columns:\n",
        "    print(f\"Correlation between RH and Tamb: {df['RH'].corr(df['Tamb']):.2f}\")\n",
        "    print(f\"Correlation between RH and GHI: {df['RH'].corr(df['GHI']):.2f}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.scatterplot(data=df, x='Tamb', y='GHI', hue='RH', palette='viridis', alpha=0.7, size='RH', sizes=(20, 400))\n",
        "    plt.title(f'GHI vs. Ambient Temperature colored by Relative Humidity for zambia')\n",
        "    plt.xlabel('Ambient Temperature (Tamb)')\n",
        "    plt.ylabel('Global Horizontal Irradiance (GHI)')\n",
        "    plt.legend(title='Relative Humidity')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping detailed temperature analysis: 'RH', 'Tamb', or 'GHI' not found.\")\n",
        "\n",
        "# --- 10. Bubble Chart ---\n",
        "print(\"\\n--- Bubble Chart Analysis ---\")\n",
        "\n",
        "if 'GHI' in df.columns and 'Tamb' in df.columns and 'RH' in df.columns:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.scatterplot(data=df, x='Tamb', y='GHI', size='RH', hue='RH', palette='viridis', sizes=(50, 1000), alpha=0.7)\n",
        "    plt.title(f'GHI vs. Ambient Temperature with Bubble Size by Relative Humidity for zambia')\n",
        "    plt.xlabel('Ambient Temperature (Tamb)')\n",
        "    plt.ylabel('Global Horizontal Irradiance (GHI)')\n",
        "    plt.legend(title='Relative Humidity', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "elif 'GHI' in df.columns and 'Tamb' in df.columns and 'BP' in df.columns:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.scatterplot(data=df, x='Tamb', y='GHI', size='BP', hue='BP', palette='cividis', sizes=(50, 1000), alpha=0.7)\n",
        "    plt.title(f'GHI vs. Ambient Temperature with Bubble Size by Barometric Pressure for zambia')\n",
        "    plt.xlabel('Ambient Temperature (Tamb)')\n",
        "    plt.ylabel('Global Horizontal Irradiance (GHI)')\n",
        "    plt.legend(title='Barometric Pressure', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Cannot generate bubble chart: Missing GHI, Tamb, and either RH or BP columns.\")\n",
        "\n",
        "print(f\"\\n--- EDA for zambia Completed ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "-iNBRW6SC1Nz",
        "outputId": "84f65021-0568-4c7c-9b36-bd891018bf83"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'windrose'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-45009e0d6f8f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwindrose\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindroseAxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# --- 1. Configuration ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'windrose'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install windrose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unfiQx1DGSal",
        "outputId": "629b5e78-7950-431d-d632-7564fa0deb90"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting windrose\n",
            "  Downloading windrose-1.9.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from windrose) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from windrose) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->windrose) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->windrose) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->windrose) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->windrose) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->windrose) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->windrose) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->windrose) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->windrose) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3->windrose) (1.17.0)\n",
            "Downloading windrose-1.9.2-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: windrose\n",
            "Successfully installed windrose-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import zscore\n",
        "import os\n",
        "from windrose import WindroseAxes\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "COUNTRY_NAME = \"Zambia\"\n",
        "DATA_PATH = f\"data/zambia.csv\"\n",
        "CLEANED_DATA_PATH = f\"data/zambia_clean.csv\"\n",
        "\n",
        "print(f\"Starting EDA for zambia\")\n",
        "print(f\"Attempting to load data from: data/zambia.csv\")\n",
        "\n",
        "# --- 2. Data Loading ---\n",
        "try:\n",
        "    df = pd.read_csv(\"data/zambia.csv\")\n",
        "    print(\"Data loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: data/zambia.csv not found. Please ensure the CSV file is in the 'data/' directory.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the data: {e}\")\n",
        "    exit()\n",
        "\n",
        "df_original = df.copy()\n",
        "\n",
        "# Convert 'Date (UTC)' to datetime and set as index\n",
        "timestamp_column_name = 'Date (UTC)'\n",
        "if timestamp_column_name in df.columns:\n",
        "    df[timestamp_column_name] = pd.to_datetime(df[timestamp_column_name], errors='coerce')\n",
        "    df.dropna(subset=[timestamp_column_name], inplace=True)\n",
        "    df.set_index(timestamp_column_name, inplace=True)\n",
        "    df.sort_index(inplace=True)\n",
        "    print(f\"{timestamp_column_name} column processed and set as index.\")\n",
        "    df.index.name = 'Timestamp'\n",
        "else:\n",
        "    print(f\"Warning: '{timestamp_column_name}' column not found. Please check your CSV column names.\")\n",
        "    print(\"Available columns:\", df.columns.tolist())\n",
        "\n",
        "# --- RENAME COLUMNS FOR CONSISTENCY WITH SCRIPT'S EXPECTATIONS ---\n",
        "# This map is based on typical IFC solar data column names.\n",
        "# If your CSV's column names differ, adjust the LEFT side of the 'key: value' pairs.\n",
        "column_rename_map = {\n",
        "    'GHI (W/m2)': 'GHI',\n",
        "    'DNI (W/m2)': 'DNI',\n",
        "    'DHI (W/m2)': 'DHI',\n",
        "    'Module Temp (C) (logger 1)': 'ModA',\n",
        "    'Module Temp (C) (logger 2)': 'ModB',\n",
        "    'Ambient Temp (C)': 'Tamb',\n",
        "    'Relative Humidity (%)': 'RH',\n",
        "    'Wind Speed (m/s)': 'WS',\n",
        "    'Wind Speed Gust (m/s)': 'WSgust',\n",
        "    'Wind Direction (deg)': 'WD',\n",
        "    'Barometric Pressure (mBar)': 'BP'\n",
        "}\n",
        "\n",
        "df.rename(columns={k: v for k, v in column_rename_map.items() if k in df.columns}, inplace=True)\n",
        "df_original.rename(columns={k: v for k, v in column_rename_map.items() if k in df_original.columns}, inplace=True)\n",
        "\n",
        "print(\"\\n--- Initial DataFrame Info ---\")\n",
        "df.info()\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# --- 3. Summary Statistics & Missing-Value Report ---\n",
        "print(\"\\n--- Summary Statistics for Numeric Columns ---\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\n--- Missing Value Report ---\")\n",
        "missing_values = df.isna().sum()\n",
        "missing_percentage = (df.isna().sum() / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_values,\n",
        "    'Missing Percentage': missing_percentage\n",
        "})\n",
        "print(missing_df[missing_df['Missing Count'] > 0].sort_values(by='Missing Percentage', ascending=False))\n",
        "\n",
        "high_null_cols = missing_percentage[missing_percentage > 5].index.tolist()\n",
        "if high_null_cols:\n",
        "    print(f\"\\nColumns with >5% nulls: {high_null_cols}\")\n",
        "else:\n",
        "    print(\"\\nNo columns with >5% nulls.\")\n",
        "\n",
        "# --- 4. Outlier Detection & Basic Cleaning ---\n",
        "print(\"\\n--- Outlier Detection and Cleaning ---\")\n",
        "\n",
        "zscore_cols = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
        "zscore_cols_existing = [col for col in zscore_cols if col in df.columns]\n",
        "\n",
        "df['cleaning_flag'] = 'original'\n",
        "\n",
        "for col in zscore_cols_existing:\n",
        "    if df[col].dtype in ['float64', 'int64']:\n",
        "        temp_series = df[col].dropna()\n",
        "        if not temp_series.empty:\n",
        "            z_scores = np.abs(zscore(temp_series))\n",
        "            outlier_mask = pd.Series(False, index=df.index)\n",
        "            outlier_mask.loc[temp_series.index] = (z_scores > 3)\n",
        "            df.loc[outlier_mask, 'cleaning_flag'] = 'outlier_flagged'\n",
        "            print(f\"Flagged {outlier_mask.sum()} outliers in column: {col}\")\n",
        "        else:\n",
        "            print(f\"Column '{col}' is entirely NaN, skipping Z-score calculation.\")\n",
        "    else:\n",
        "        print(f\"Skipping Z-score for non-numeric column: {col}\")\n",
        "\n",
        "\n",
        "key_columns_for_imputation = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust', 'Tamb', 'RH', 'BP']\n",
        "key_columns_for_imputation_existing = [col for col in key_columns_for_imputation if col in df.columns]\n",
        "\n",
        "for col in key_columns_for_imputation_existing:\n",
        "    if df[col].isna().sum() > 0:\n",
        "        if df[col].dtype in ['float64', 'int64']:\n",
        "            median_val = df[col].median()\n",
        "            df[col].fillna(median_val, inplace=True)\n",
        "            print(f\"Imputed missing values in '{col}' with median: {median_val:.2f}\")\n",
        "        else:\n",
        "            print(f\"Skipping imputation for non-numeric column with NaNs: {col}\")\n",
        "\n",
        "print(\"\\n--- Missing Value Report After Imputation ---\")\n",
        "print(df.isna().sum()[df.isna().sum() > 0])\n",
        "if df.isna().sum().sum() == 0:\n",
        "    print(\"No missing values remaining in the DataFrame.\")\n",
        "else:\n",
        "    print(\"Some missing values still remain (likely in non-key columns or after timestamp processing).\")\n",
        "\n",
        "try:\n",
        "    df.to_csv(CLEANED_DATA_PATH, index=True)\n",
        "    print(f\"\\nCleaned DataFrame exported to: {CLEANED_DATA_PATH}\")\n",
        "    print(\"Remember to add 'data/' to your .gitignore file to prevent committing CSVs.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error exporting cleaned data: {e}\")\n",
        "\n",
        "# --- 5. Time Series Analysis ---\n",
        "print(\"\\n--- Time Series Analysis ---\")\n",
        "\n",
        "time_series_cols = ['GHI', 'DNI', 'DHI', 'Tamb']\n",
        "time_series_cols_existing = [col for col in time_series_cols if col in df.columns]\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "for i, col in enumerate(time_series_cols_existing):\n",
        "    plt.subplot(len(time_series_cols_existing), 1, i + 1)\n",
        "    df[col].plot(title=f'{col} Over Time for zambia', grid=True)\n",
        "    plt.ylabel(col)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "if 'GHI' in df.columns:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    df['GHI'].resample('M').mean().plot(kind='bar', title=f'Average Monthly GHI for zambia', grid=True)\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel('Average GHI')\n",
        "    plt.show()\n",
        "\n",
        "if 'GHI' in df.columns:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    df.groupby(df.index.hour)['GHI'].mean().plot(title=f'Average Hourly GHI for zambia', grid=True)\n",
        "    plt.xlabel('Hour of Day')\n",
        "    plt.ylabel('Average GHI')\n",
        "    plt.xticks(range(0, 24))\n",
        "    plt.show()\n",
        "\n",
        "# --- 6. Cleaning Impact ---\n",
        "print(\"\\n--- Cleaning Impact Analysis ---\")\n",
        "\n",
        "if 'cleaning_flag' in df.columns and 'ModA' in df.columns and 'ModB' in df.columns:\n",
        "    df_original_flagged = df_original.copy()\n",
        "    if timestamp_column_name in df_original_flagged.columns:\n",
        "        df_original_flagged[timestamp_column_name] = pd.to_datetime(df_original_flagged[timestamp_column_name], errors='coerce')\n",
        "        df_original_flagged.dropna(subset=[timestamp_column_name], inplace=True)\n",
        "        df_original_flagged.set_index(timestamp_column_name, inplace=True)\n",
        "        df_original_flagged.index.name = 'Timestamp'\n",
        "\n",
        "    df_original_flagged['cleaning_flag_pre_clean'] = 'original'\n",
        "    for col in zscore_cols_existing:\n",
        "        if col in df_original_flagged.columns and df_original_flagged[col].dtype in ['float64', 'int64']:\n",
        "            temp_series_orig = df_original_flagged[col].dropna()\n",
        "            if not temp_series_orig.empty:\n",
        "                z_scores_orig = np.abs(zscore(temp_series_orig))\n",
        "                outlier_mask_orig = pd.Series(False, index=df_original_flagged.index)\n",
        "                outlier_mask_orig.loc[temp_series_orig.index] = (z_scores_orig > 3)\n",
        "                df_original_flagged.loc[outlier_mask_orig, 'cleaning_flag_pre_clean'] = 'outlier_flagged'\n",
        "            else:\n",
        "                print(f\"Original column '{col}' is entirely NaN, skipping outlier flagging for comparison.\")\n",
        "\n",
        "    print(\"\\nAverage ModA & ModB (Original Data, grouped by potential outlier flag):\")\n",
        "    if 'ModA' in df_original_flagged.columns and 'ModB' in df_original_flagged.columns:\n",
        "        print(df_original_flagged.groupby('cleaning_flag_pre_clean')[['ModA', 'ModB']].mean())\n",
        "    else:\n",
        "        print(\"ModA or ModB not found in original data for cleaning impact analysis.\")\n",
        "\n",
        "\n",
        "    print(\"\\nAverage ModA & ModB (Cleaned Data, overall mean after imputation):\")\n",
        "    if 'ModA' in df.columns and 'ModB' in df.columns:\n",
        "        print(df[['ModA', 'ModB']].mean())\n",
        "    else:\n",
        "        print(\"ModA or ModB not found in cleaned data for cleaning impact analysis.\")\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    if 'ModA' in df.columns and 'ModA' in df_original_flagged.columns:\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.histplot(df_original_flagged['ModA'].dropna(), color='skyblue', label='Original ModA', kde=True)\n",
        "        sns.histplot(df['ModA'], color='orange', label='Cleaned ModA', kde=True)\n",
        "        plt.title(f'Distribution of ModA (Original vs. Cleaned) for {COUNTRY_NAME}')\n",
        "        plt.legend()\n",
        "\n",
        "    if 'ModB' in df.columns and 'ModB' in df_original_flagged.columns:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        sns.histplot(df_original_flagged['ModB'].dropna(), color='lightgreen', label='Original ModB', kde=True)\n",
        "        sns.histplot(df['ModB'], color='red', label='Cleaned ModB', kde=True)\n",
        "        plt.title(f'Distribution of ModB (Original vs. Cleaned) for zambia')\n",
        "        plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Cannot perform cleaning impact analysis: 'cleaning_flag', 'ModA', or 'ModB' column missing.\")\n",
        "\n",
        "# --- 7. Correlation & Relationship Analysis ---\n",
        "print(\"\\n--- Correlation & Relationship Analysis ---\")\n",
        "\n",
        "correlation_cols = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'Tamb', 'RH', 'WS', 'WSgust', 'WD', 'BP']\n",
        "correlation_cols_existing = [col for col in correlation_cols if col in df.columns]\n",
        "\n",
        "if len(correlation_cols_existing) > 1:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(df[correlation_cols_existing].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title(f'Correlation Heatmap for zambia')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Not enough numeric columns for correlation heatmap.\")\n",
        "\n",
        "scatter_plots_config = [\n",
        "    {'x': 'WS', 'y': 'GHI'},\n",
        "    {'x': 'WSgust', 'y': 'GHI'},\n",
        "    {'x': 'WD', 'y': 'GHI'},\n",
        "    {'x': 'RH', 'y': 'Tamb'},\n",
        "    {'x': 'RH', 'y': 'GHI'}\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(18, 12))\n",
        "for i, config in enumerate(scatter_plots_config):\n",
        "    x_col = config['x']\n",
        "    y_col = config['y']\n",
        "    if x_col in df.columns and y_col in df.columns:\n",
        "        plt.subplot(2, 3, i + 1)\n",
        "        sns.scatterplot(data=df, x=x_col, y=y_col, alpha=0.6)\n",
        "        plt.title(f'{y_col} vs. {x_col} for zambia')\n",
        "        plt.xlabel(x_col)\n",
        "        plt.ylabel(y_col)\n",
        "    else:\n",
        "        print(f\"Skipping scatter plot: '{x_col}' or '{y_col}' not found.\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 8. Wind & Distribution Analysis ---\n",
        "print(\"\\n--- Wind & Distribution Analysis ---\")\n",
        "\n",
        "if 'WS' in df.columns and 'WD' in df.columns:\n",
        "    try:\n",
        "        ax = WindroseAxes.from_ax()\n",
        "        ax.bar(df['WD'], df['WS'], normed=True, opening=0.8, edgecolor='white')\n",
        "        ax.set_legend()\n",
        "        plt.title(f'Wind Rose Plot for zambia')\n",
        "        plt.show()\n",
        "        print(\"Wind rose plot generated.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate wind rose plot (might need 'windrose' library or data issues): {e}\")\n",
        "else:\n",
        "    print(\"Skipping wind rose plot: 'WS' or 'WD' column not found.\")\n",
        "\n",
        "histogram_cols = ['GHI', 'WS']\n",
        "histogram_cols_existing = [col for col in histogram_cols if col in df.columns]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "for i, col in enumerate(histogram_cols_existing):\n",
        "    plt.subplot(1, len(histogram_cols_existing), i + 1)\n",
        "    sns.histplot(df[col].dropna(), kde=True)\n",
        "    plt.title(f'Distribution of {col} for zambia')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 9. Temperature Analysis ---\n",
        "print(\"\\n--- Temperature Analysis ---\")\n",
        "\n",
        "if 'RH' in df.columns and 'Tamb' in df.columns and 'GHI' in df.columns:\n",
        "    print(f\"Correlation between RH and Tamb: {df['RH'].corr(df['Tamb']):.2f}\")\n",
        "    print(f\"Correlation between RH and GHI: {df['RH'].corr(df['GHI']):.2f}\")\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.scatterplot(data=df, x='Tamb', y='GHI', hue='RH', palette='viridis', alpha=0.7, size='RH', sizes=(20, 400))\n",
        "    plt.title(f'GHI vs. Ambient Temperature colored by Relative Humidity for zambia')\n",
        "    plt.xlabel('Ambient Temperature (Tamb)')\n",
        "    plt.ylabel('Global Horizontal Irradiance (GHI)')\n",
        "    plt.legend(title='Relative Humidity')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping detailed temperature analysis: 'RH', 'Tamb', or 'GHI' not found.\")\n",
        "\n",
        "# --- 10. Bubble Chart ---\n",
        "print(\"\\n--- Bubble Chart Analysis ---\")\n",
        "\n",
        "if 'GHI' in df.columns and 'Tamb' in df.columns and 'RH' in df.columns:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.scatterplot(data=df, x='Tamb', y='GHI', size='RH', hue='RH', palette='viridis', sizes=(50, 1000), alpha=0.7)\n",
        "    plt.title(f'GHI vs. Ambient Temperature with Bubble Size by Relative Humidity for zambia')\n",
        "    plt.xlabel('Ambient Temperature (Tamb)')\n",
        "    plt.ylabel('Global Horizontal Irradiance (GHI)')\n",
        "    plt.legend(title='Relative Humidity', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "elif 'GHI' in df.columns and 'Tamb' in df.columns and 'BP' in df.columns:\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.scatterplot(data=df, x='Tamb', y='GHI', size='BP', hue='BP', palette='cividis', sizes=(50, 1000), alpha=0.7)\n",
        "    plt.title(f'GHI vs. Ambient Temperature with Bubble Size by Barometric Pressure for zambia')\n",
        "    plt.xlabel('Ambient Temperature (Tamb)')\n",
        "    plt.ylabel('Global Horizontal Irradiance (GHI)')\n",
        "    plt.legend(title='Barometric Pressure', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Cannot generate bubble chart: Missing GHI, Tamb, and either RH or BP columns.\")\n",
        "\n",
        "print(f\"\\n--- EDA for zambia Completed ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hLR9wFeVGaCY",
        "outputId": "c1cefc40-444f-449b-85ec-6d35f45b4686"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting EDA for zambia\n",
            "Attempting to load data from: data/zambia.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-9ad7424cc39a>:19: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"data/zambia.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Warning: 'Date (UTC)' column not found. Please check your CSV column names.\n",
            "Available columns: ['time', 'dhi_pyr', 'ghi_pyr_1', 'ghi_pyr_2', 'air_temperature', 'relative_humidity', 'barometric_pressure', 'precipitation', 'wind_speed', 'wind_from_direction', 'gti_clean', 'gti_soil', 'sensor_cleaning', 'comments']\n",
            "\n",
            "--- Initial DataFrame Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 550080 entries, 0 to 550079\n",
            "Data columns (total 14 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   time                 550080 non-null  object \n",
            " 1   dhi_pyr              548875 non-null  float64\n",
            " 2   ghi_pyr_1            550054 non-null  float64\n",
            " 3   ghi_pyr_2            550054 non-null  float64\n",
            " 4   air_temperature      550054 non-null  float64\n",
            " 5   relative_humidity    550054 non-null  float64\n",
            " 6   barometric_pressure  550054 non-null  float64\n",
            " 7   precipitation        550054 non-null  float64\n",
            " 8   wind_speed           550054 non-null  float64\n",
            " 9   wind_from_direction  550054 non-null  float64\n",
            " 10  gti_clean            550054 non-null  float64\n",
            " 11  gti_soil             550054 non-null  float64\n",
            " 12  sensor_cleaning      550054 non-null  float64\n",
            " 13  comments             1205 non-null    object \n",
            "dtypes: float64(12), object(2)\n",
            "memory usage: 58.8+ MB\n",
            "\n",
            "First 5 rows:\n",
            "               time  dhi_pyr  ghi_pyr_1  ghi_pyr_2  air_temperature  \\\n",
            "0  2017-08-15 00:01      0.0        0.0        0.0             7.84   \n",
            "1  2017-08-15 00:02      0.0        0.0        0.0             7.93   \n",
            "2  2017-08-15 00:03      0.0        0.0        0.0             7.85   \n",
            "3  2017-08-15 00:04      0.0        0.0        0.0             7.78   \n",
            "4  2017-08-15 00:05      0.0        0.0        0.0             7.75   \n",
            "\n",
            "   relative_humidity  barometric_pressure  precipitation  wind_speed  \\\n",
            "0               87.4               892.41            0.0        1.39   \n",
            "1               84.4               892.37            0.0        1.35   \n",
            "2               81.9               892.36            0.0        1.45   \n",
            "3               83.7               892.35            0.0        1.54   \n",
            "4               85.6               892.35            0.0        1.53   \n",
            "\n",
            "   wind_from_direction  gti_clean  gti_soil  sensor_cleaning comments  \n",
            "0                34.61        0.0       0.0              0.0      NaN  \n",
            "1                39.02        0.0       0.0              0.0      NaN  \n",
            "2                46.05        0.0       0.0              0.0      NaN  \n",
            "3                46.37        0.0       0.0              0.0      NaN  \n",
            "4                35.15        0.0       0.0              0.0      NaN  \n",
            "\n",
            "--- Summary Statistics for Numeric Columns ---\n",
            "             dhi_pyr      ghi_pyr_1      ghi_pyr_2  air_temperature  \\\n",
            "count  548875.000000  550054.000000  550054.000000    550054.000000   \n",
            "mean       77.131812     235.661466     233.901828        20.488666   \n",
            "std       117.531753     334.344013     332.016837         6.231868   \n",
            "min         0.000000       0.000000       0.000000         1.000000   \n",
            "25%         0.000000       0.000000       0.000000        16.960000   \n",
            "50%         2.580000       2.590000       2.510000        20.570000   \n",
            "75%       115.340000     428.897500     425.570000        24.920000   \n",
            "max       799.500000    1624.000000    1613.300000        39.920000   \n",
            "\n",
            "       relative_humidity  barometric_pressure  precipitation     wind_speed  \\\n",
            "count      550054.000000        550054.000000  550054.000000  550054.000000   \n",
            "mean           69.262470           889.126571       0.001348       2.608212   \n",
            "std            25.165622             3.259002       0.027198       1.593271   \n",
            "min             8.150000           879.430000       0.000000       0.000000   \n",
            "25%            48.330000           886.700000       0.000000       1.490000   \n",
            "50%            72.710000           888.990000       0.000000       2.300000   \n",
            "75%            93.900000           891.330000       0.000000       3.610000   \n",
            "max           100.000000           899.620000       3.000000      12.450000   \n",
            "\n",
            "       wind_from_direction      gti_clean      gti_soil  sensor_cleaning  \n",
            "count        550054.000000  550054.000000  550054.00000    550054.000000  \n",
            "mean            121.547282     239.526369     237.13630         0.000267  \n",
            "std              74.427336     341.916171     338.27057         0.016346  \n",
            "min               0.000000       0.000000       0.00000         0.000000  \n",
            "25%              74.910000       0.000000       0.00000         0.000000  \n",
            "50%             100.600000       4.430000       3.97000         0.000000  \n",
            "75%             143.600000     429.660000     426.85000         0.000000  \n",
            "max             360.000000    1569.270000    1573.73000         1.000000  \n",
            "\n",
            "--- Missing Value Report ---\n",
            "                     Missing Count  Missing Percentage\n",
            "comments                    548875           99.780941\n",
            "dhi_pyr                       1205            0.219059\n",
            "ghi_pyr_1                       26            0.004727\n",
            "air_temperature                 26            0.004727\n",
            "ghi_pyr_2                       26            0.004727\n",
            "relative_humidity               26            0.004727\n",
            "barometric_pressure             26            0.004727\n",
            "wind_speed                      26            0.004727\n",
            "precipitation                   26            0.004727\n",
            "wind_from_direction             26            0.004727\n",
            "gti_clean                       26            0.004727\n",
            "gti_soil                        26            0.004727\n",
            "sensor_cleaning                 26            0.004727\n",
            "\n",
            "Columns with >5% nulls: ['comments']\n",
            "\n",
            "--- Outlier Detection and Cleaning ---\n",
            "\n",
            "--- Missing Value Report After Imputation ---\n",
            "dhi_pyr                  1205\n",
            "ghi_pyr_1                  26\n",
            "ghi_pyr_2                  26\n",
            "air_temperature            26\n",
            "relative_humidity          26\n",
            "barometric_pressure        26\n",
            "precipitation              26\n",
            "wind_speed                 26\n",
            "wind_from_direction        26\n",
            "gti_clean                  26\n",
            "gti_soil                   26\n",
            "sensor_cleaning            26\n",
            "comments               548875\n",
            "dtype: int64\n",
            "Some missing values still remain (likely in non-key columns or after timestamp processing).\n",
            "\n",
            "Cleaned DataFrame exported to: data/zambia_clean.csv\n",
            "Remember to add 'data/' to your .gitignore file to prevent committing CSVs.\n",
            "\n",
            "--- Time Series Analysis ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cleaning Impact Analysis ---\n",
            "Cannot perform cleaning impact analysis: 'cleaning_flag', 'ModA', or 'ModB' column missing.\n",
            "\n",
            "--- Correlation & Relationship Analysis ---\n",
            "Not enough numeric columns for correlation heatmap.\n",
            "Skipping scatter plot: 'WS' or 'GHI' not found.\n",
            "Skipping scatter plot: 'WSgust' or 'GHI' not found.\n",
            "Skipping scatter plot: 'WD' or 'GHI' not found.\n",
            "Skipping scatter plot: 'RH' or 'Tamb' not found.\n",
            "Skipping scatter plot: 'RH' or 'GHI' not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Wind & Distribution Analysis ---\n",
            "Skipping wind rose plot: 'WS' or 'WD' column not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Temperature Analysis ---\n",
            "Skipping detailed temperature analysis: 'RH', 'Tamb', or 'GHI' not found.\n",
            "\n",
            "--- Bubble Chart Analysis ---\n",
            "Cannot generate bubble chart: Missing GHI, Tamb, and either RH or BP columns.\n",
            "\n",
            "--- EDA for zambia Completed ---\n"
          ]
        }
      ]
    }
  ]
}